{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "554ea1ec-1dfb-4759-ab03-9e56d34e5fde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SILVER LAYER - Data Cleaning, Validation, and Enrichment\n",
    "# Purpose: Create clean, joined, business-ready tables\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "print(\"Starting Silver Layer transformations...\")\n",
    "\n",
    "# ============================================\n",
    "# 1. CLEAN ORDERS TABLE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n1. Processing Orders...\")\n",
    "\n",
    "orders = spark.table(\"bronze_orders\")\n",
    "\n",
    "# Check initial count\n",
    "print(f\"   Raw orders: {orders.count()}\")\n",
    "\n",
    "# Filter only delivered orders\n",
    "orders_clean = orders.filter(F.col(\"order_status\") == \"delivered\")\n",
    "print(f\"   Delivered orders: {orders_clean.count()}\")\n",
    "\n",
    "# Convert timestamps\n",
    "date_columns = [\n",
    "    \"order_purchase_timestamp\",\n",
    "    \"order_approved_at\",\n",
    "    \"order_delivered_carrier_date\",\n",
    "    \"order_delivered_customer_date\",\n",
    "    \"order_estimated_delivery_date\"\n",
    "]\n",
    "\n",
    "for col in date_columns:\n",
    "    orders_clean = orders_clean.withColumn(col, F.to_timestamp(col))\n",
    "\n",
    "# Calculate delivery time in days\n",
    "orders_clean = orders_clean.withColumn(\n",
    "    \"delivery_days\",\n",
    "    F.datediff(F.col(\"order_delivered_customer_date\"), F.col(\"order_purchase_timestamp\"))\n",
    ")\n",
    "\n",
    "# Calculate delivery delay (negative = early, positive = late)\n",
    "orders_clean = orders_clean.withColumn(\n",
    "    \"delivery_delay_days\",\n",
    "    F.datediff(F.col(\"order_delivered_customer_date\"), F.col(\"order_estimated_delivery_date\"))\n",
    ")\n",
    "\n",
    "orders_clean.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_orders\")\n",
    "print(\"   âœ“ Created silver_orders\")\n",
    "\n",
    "# ============================================\n",
    "# 2. ENRICH ORDER ITEMS WITH PRODUCT INFO\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n2. Processing Order Items with Products...\")\n",
    "\n",
    "order_items = spark.table(\"workspace.default.bronze_order_items\")\n",
    "products = spark.table(\"workspace.default.bronze_products\")\n",
    "translations = spark.table(\"workspace.default.bronze_product_category_translation\")\n",
    "\n",
    "print(f\"   Order items: {order_items.count()}\")\n",
    "\n",
    "# Join products with translations (remove ingestion_timestamp to avoid conflicts)\n",
    "products_enriched = products.join(\n",
    "    translations,\n",
    "    products.product_category_name == translations.product_category_name,\n",
    "    \"left\"\n",
    ").select(\n",
    "    products.product_id,\n",
    "    products.product_category_name,\n",
    "    products.product_name_lenght,\n",
    "    products.product_description_lenght,\n",
    "    products.product_photos_qty,\n",
    "    products.product_weight_g,\n",
    "    products.product_length_cm,\n",
    "    products.product_height_cm,\n",
    "    products.product_width_cm,\n",
    "    translations.product_category_name_english.alias(\"category_english\")\n",
    ")\n",
    "\n",
    "# Join order items with enriched products (drop ingestion_timestamp from order_items to avoid duplicates)\n",
    "order_items_clean = order_items.drop(\"ingestion_timestamp\")\n",
    "\n",
    "order_items_enriched = order_items_clean.join(\n",
    "    products_enriched,\n",
    "    \"product_id\",\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "order_items_enriched.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.default.silver_order_items\")\n",
    "print(\"   âœ“ Created silver_order_items\")\n",
    "\n",
    "# ============================================\n",
    "# 3. AGGREGATE PAYMENTS BY ORDER\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n3. Processing Payments...\")\n",
    "\n",
    "payments = spark.table(\"bronze_order_payments\")\n",
    "print(f\"   Payment records: {payments.count()}\")\n",
    "\n",
    "# Aggregate payments per order\n",
    "payments_agg = payments.groupBy(\"order_id\").agg(\n",
    "    F.sum(\"payment_value\").alias(\"total_payment_value\"),\n",
    "    F.count(\"*\").alias(\"payment_installments_count\"),\n",
    "    F.first(\"payment_type\").alias(\"primary_payment_type\")\n",
    ")\n",
    "\n",
    "payments_agg.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_order_payments\")\n",
    "print(\"   âœ“ Created silver_order_payments\")\n",
    "\n",
    "# ============================================\n",
    "# 4. AGGREGATE REVIEWS BY ORDER\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n4. Processing Reviews...\")\n",
    "\n",
    "reviews = spark.table(\"bronze_order_reviews\")\n",
    "print(f\"   Review records: {reviews.count()}\")\n",
    "\n",
    "# Use try_cast for handling malformed values\n",
    "reviews = reviews.withColumn(\n",
    "    \"review_score_clean\", \n",
    "    F.expr(\"try_cast(review_score as double)\")\n",
    ")\n",
    "\n",
    "# Filter valid score-only reviews\n",
    "reviews_valid = reviews.filter(F.col(\"review_score_clean\").isNotNull())\n",
    "\n",
    "# Clean and aggregate reviews\n",
    "reviews_agg = reviews_valid.groupBy(\"order_id\").agg(\n",
    "    F.avg(\"review_score_clean\").alias(\"avg_review_score\"),\n",
    "    F.max(\"review_score_clean\").alias(\"max_review_score\"),\n",
    "    F.min(\"review_score_clean\").alias(\"min_review_score\"),\n",
    "    F.count(\"*\").alias(\"review_count\")\n",
    ")\n",
    "\n",
    "reviews_agg.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_order_reviews\")\n",
    "\n",
    "# Quality check: show how many records were filtered\n",
    "total_reviews = reviews.count()\n",
    "valid_reviews = reviews_valid.count()\n",
    "print(f\"   Total reviews: {total_reviews}\")\n",
    "print(f\"   Valid reviews: {valid_reviews}\")\n",
    "print(f\"   Invalid reviews (filtered out): {total_reviews - valid_reviews}\")\n",
    "\n",
    "print(\"   âœ“ Created silver_order_reviews\")\n",
    "\n",
    "# ============================================\n",
    "# 5. CREATE MASTER ORDER TABLE (FACT TABLE)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n5. Creating Master Orders Fact Table...\")\n",
    "\n",
    "# Start with clean orders\n",
    "master = spark.table(\"silver_orders\")\n",
    "\n",
    "# Drop ingestion_timestamp from customers before join\n",
    "customers = spark.table(\"bronze_customers\").drop(\"ingestion_timestamp\")\n",
    "master = master.join(customers, \"customer_id\", \"left\")\n",
    "\n",
    "# Drop ingestion_timestamp from payments_agg before join\n",
    "payments_agg = spark.table(\"silver_order_payments\").drop(\"ingestion_timestamp\")\n",
    "master = master.join(payments_agg, \"order_id\", \"left\")\n",
    "\n",
    "# Drop ingestion_timestamp from reviews_agg before join\n",
    "reviews_agg = spark.table(\"silver_order_reviews\").drop(\"ingestion_timestamp\")\n",
    "master = master.join(reviews_agg, \"order_id\", \"left\")\n",
    "\n",
    "# Drop ingestion_timestamp from silver_order_items before aggregation\n",
    "order_metrics = spark.table(\"silver_order_items\").drop(\"ingestion_timestamp\").groupBy(\"order_id\").agg(\n",
    "    F.sum(\"price\").alias(\"total_items_price\"),\n",
    "    F.sum(\"freight_value\").alias(\"total_freight_value\"),\n",
    "    F.count(\"*\").alias(\"items_count\"),\n",
    "    F.countDistinct(\"product_id\").alias(\"unique_products_count\")\n",
    ")\n",
    "master = master.join(order_metrics, \"order_id\", \"left\")\n",
    "\n",
    "# Calculate total order value\n",
    "master = master.withColumn(\n",
    "    \"order_total_value\",\n",
    "    F.coalesce(F.col(\"total_payment_value\"), F.col(\"total_items_price\") + F.col(\"total_freight_value\"))\n",
    ")\n",
    "\n",
    "master.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"silver_orders_master\")\n",
    "print(f\"   âœ“ Created silver_orders_master with {master.count()} orders\")\n",
    "\n",
    "# Show sample of master table\n",
    "print(\"\\nSample of silver_orders_master:\")\n",
    "spark.table(\"silver_orders_master\").select(\n",
    "    \"order_id\", \"customer_unique_id\", \"order_total_value\", \n",
    "    \"delivery_days\", \"avg_review_score\", \"items_count\"\n",
    ").show(5)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Silver layer complete! Data is cleaned, joined, and ready for analytics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6fe7837-ab68-42e6-9c9c-f41000887522",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DROP TABLE IF EXISTS silver_orders;\n",
    "DROP TABLE IF EXISTS workspace.default.silver_order_items;\n",
    "DROP TABLE IF EXISTS silver_order_payments;\n",
    "DROP TABLE IF EXISTS silver_order_reviews;\n",
    "DROP TABLE IF EXISTS silver_orders_master;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7829855386541578,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Silver_Layer_Transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
