{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c4f064b-312d-430b-81f5-d5f2c822af5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MACHINE LEARNING - Customer Segmentation using K-Means\n",
    "# Purpose: Create data-driven customer segments\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Load customer metrics\n",
    "customer_data = spark.table(\"gold_customer_metrics\")\n",
    "\n",
    "# Select fewer features for clustering\n",
    "features = [\"recency_days\", \"frequency\", \"monetary_value\"]\n",
    "\n",
    "# Prepare data\n",
    "ml_data = customer_data.select(\n",
    "    \"customer_unique_id\",\n",
    "    *features\n",
    ").na.drop()\n",
    "\n",
    "# Sample data to reduce model size further\n",
    "ml_data_sampled = ml_data.sample(\n",
    "    fraction=0.1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Training on {ml_data_sampled.count()} customers (sampled)\")\n",
    "\n",
    "# Feature engineering pipeline\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=features,\n",
    "    outputCol=\"features_raw\"\n",
    ")\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features_raw\",\n",
    "    outputCol=\"features\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# K-Means clustering (k=3 segments)\n",
    "kmeans = KMeans(\n",
    "    k=3,\n",
    "    seed=42,\n",
    "    featuresCol=\"features\",\n",
    "    predictionCol=\"ml_segment\"\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline(\n",
    "    stages=[assembler, scaler, kmeans]\n",
    ")\n",
    "\n",
    "# Train model\n",
    "print(\"Training K-Means model...\")\n",
    "model = pipeline.fit(ml_data_sampled)\n",
    "predictions = model.transform(ml_data)\n",
    "\n",
    "# Analyze segments\n",
    "segment_analysis = predictions.groupBy(\"ml_segment\").agg(\n",
    "    F.count(\"*\").alias(\"customer_count\"),\n",
    "    F.avg(\"recency_days\").alias(\"avg_recency\"),\n",
    "    F.avg(\"frequency\").alias(\"avg_frequency\"),\n",
    "    F.avg(\"monetary_value\").alias(\"avg_monetary\")\n",
    ").orderBy(\"ml_segment\")\n",
    "\n",
    "display(segment_analysis)\n",
    "\n",
    "# Save predictions\n",
    "predictions.select(\n",
    "    \"customer_unique_id\",\n",
    "    \"ml_segment\"\n",
    ").write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"gold_customer_segments_ml\")\n",
    "\n",
    "print(\"âœ“ Created gold_customer_segments_ml\")\n",
    "print(\"\\nðŸŽ‰ Machine Learning complete! Customer segments created.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_ML_Customer_Segmentation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
