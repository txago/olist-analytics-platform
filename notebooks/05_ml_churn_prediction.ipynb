{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8e36ebe-b54e-4ceb-b3f3-8c1031c52ea4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# MACHINE LEARNING - Churn Prediction\n",
    "# Purpose: Predict which customers are likely to churn\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import percent_rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Machine Learning: Churn Prediction Model\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load data\n",
    "customer_data = spark.table(\"workspace.default.gold_customer_metrics\")\n",
    "\n",
    "# ============================================\n",
    "# CHURN DEFINITION\n",
    "# ============================================\n",
    "\n",
    "# For e-commerce, 180 days (6 months) is more realistic\n",
    "churn_threshold = 180 \n",
    "\n",
    "print(f\"\\nðŸ“Š Churn Definition: Customer inactive for {churn_threshold}+ days\")\n",
    "\n",
    "# Create target variable\n",
    "customer_data = customer_data.withColumn(\n",
    "    \"is_churned\",\n",
    "    F.when(F.col(\"recency_days\") > churn_threshold, 1).otherwise(0)\n",
    ")\n",
    "\n",
    "# Verify churn distribution\n",
    "churn_distribution = customer_data.groupBy(\"is_churned\").count()\n",
    "total_customers = customer_data.count()\n",
    "\n",
    "print(\"\\nðŸ“ˆ Churn Distribution:\")\n",
    "churn_distribution.show()\n",
    "\n",
    "churn_count = customer_data.filter(\"is_churned = 1\").count()\n",
    "churn_rate = (churn_count / total_customers) * 100\n",
    "print(f\"   Churn Rate: {churn_rate:.2f}%\")\n",
    "print(f\"   Active Customers: {total_customers - churn_count:,}\")\n",
    "print(f\"   Churned Customers: {churn_count:,}\")\n",
    "\n",
    "# Feature engineering\n",
    "features_for_model = [\n",
    "    \"recency_days\",\n",
    "    \"frequency\",\n",
    "    \"monetary_value\",\n",
    "    \"avg_order_value\",\n",
    "    \"avg_delivery_days\",\n",
    "    \"avg_delivery_delay\",\n",
    "    \"avg_review_score\",\n",
    "    \"customer_lifetime_days\",\n",
    "    \"total_items_purchased\"\n",
    "]\n",
    "\n",
    "# Prepare training data (remove nulls and cast to double)\n",
    "ml_data = customer_data.select(\n",
    "    \"customer_unique_id\",\n",
    "    F.col(\"is_churned\").cast(\"double\").alias(\"is_churned\"),\n",
    "    *[F.col(c).cast(\"double\").alias(c) for c in features_for_model]\n",
    ").na.drop()\n",
    "\n",
    "# Split data\n",
    "train_data, test_data = ml_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"\\nðŸ“š Dataset Split:\")\n",
    "print(f\"   Training set: {train_data.count():,} customers\")\n",
    "print(f\"   Test set: {test_data.count():,} customers\")\n",
    "\n",
    "# Build pipeline\n",
    "assembler = VectorAssembler(inputCols=features_for_model, outputCol=\"features_raw\")\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    labelCol=\"is_churned\",\n",
    "    featuresCol=\"features\",\n",
    "    numTrees=10,\n",
    "    maxDepth=5,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, scaler, rf])\n",
    "\n",
    "# Train model\n",
    "print(\"\\nðŸ”„ Training Random Forest model...\")\n",
    "model = pipeline.fit(train_data)\n",
    "print(\"   âœ… Model trained successfully!\")\n",
    "\n",
    "# Make predictions on ALL customers\n",
    "print(\"\\nðŸ”® Making predictions on all customers...\")\n",
    "predictions = model.transform(ml_data)\n",
    "\n",
    "# Extract churn probability using a UDF\n",
    "@F.udf(\"double\")\n",
    "def extract_probability(probability):\n",
    "    \"\"\"Extract probability of positive class (churn=1)\"\"\"\n",
    "    if probability is not None:\n",
    "        return float(probability[1])\n",
    "    return 0.0\n",
    "\n",
    "predictions = predictions.withColumn(\n",
    "    \"churn_probability\",\n",
    "    extract_probability(F.col(\"probability\"))\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# PREDICTED CHURN\n",
    "# ============================================\n",
    "\n",
    "# Create predicted_churn based on probability,\n",
    "# using 0.5 (50%) as threshold for classification\n",
    "predictions = predictions.withColumn(\n",
    "    \"predicted_churn\",\n",
    "    F.when(F.col(\"churn_probability\") >= 0.5, 1).otherwise(0).cast(\"int\")\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# RISK CATEGORIES\n",
    "# ============================================\n",
    "\n",
    "# Calculate risk percentile\n",
    "window_spec = Window.orderBy(F.col(\"churn_probability\").desc())\n",
    "\n",
    "predictions = predictions.withColumn(\n",
    "    \"churn_percentile\",\n",
    "    percent_rank().over(window_spec)\n",
    ")\n",
    "\n",
    "# Divide categories based in percentiles\n",
    "predictions = predictions.withColumn(\n",
    "    \"churn_risk_category\",\n",
    "    F.when(F.col(\"churn_percentile\") <= 0.20, \"High Risk\")      # Top 20%\n",
    "     .when(F.col(\"churn_percentile\") <= 0.50, \"Medium Risk\")    # Next 30%\n",
    "     .otherwise(\"Low Risk\")                                     # Bottom 50%\n",
    ")\n",
    "\n",
    "# Select only necessary columns\n",
    "predictions_final = predictions.select(\n",
    "    \"customer_unique_id\",\n",
    "    F.col(\"is_churned\").cast(\"int\").alias(\"is_churned\"),\n",
    "    \"churn_probability\",\n",
    "    \"churn_risk_category\",\n",
    "    \"predicted_churn\"\n",
    ")\n",
    "\n",
    "# Save predictions\n",
    "predictions_final.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"workspace.default.gold_customer_churn_predictions\")\n",
    "\n",
    "print(\"   âœ… Created gold_customer_churn_predictions\")\n",
    "\n",
    "# ============================================\n",
    "# METRICS AND ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nðŸ“ˆ Model Evaluation:\")\n",
    "test_predictions = model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"is_churned\", \n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "auc = evaluator.evaluate(test_predictions)\n",
    "print(f\"   AUC-ROC Score: {auc:.3f}\")\n",
    "\n",
    "# Show risk distribution\n",
    "print(\"\\nðŸ“Š Churn Risk Distribution:\")\n",
    "risk_dist = predictions_final.groupBy(\"churn_risk_category\") \\\n",
    "    .agg(\n",
    "        F.count(\"*\").alias(\"customer_count\"),\n",
    "        F.avg(\"churn_probability\").alias(\"avg_probability\")\n",
    "    ) \\\n",
    "    .orderBy(F.desc(\"avg_probability\"))\n",
    "\n",
    "risk_dist.show()\n",
    "\n",
    "# Churn rate by predicted_churn\n",
    "print(\"\\nðŸŽ¯ Predicted Churn Summary:\")\n",
    "pred_summary = predictions_final.groupBy(\"predicted_churn\").count()\n",
    "pred_summary.show()\n",
    "\n",
    "predicted_churn_count = predictions_final.filter(\"predicted_churn = 1\").count()\n",
    "predicted_churn_rate = (predicted_churn_count / predictions_final.count()) * 100\n",
    "print(f\"   Predicted Churn Rate: {predicted_churn_rate:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ‰ Churn Prediction Complete!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nKey Takeaways:\")\n",
    "print(f\"  â€¢ Definition: Churn = {churn_threshold}+ days inactive\")\n",
    "print(f\"  â€¢ Actual Churn Rate: {churn_rate:.2f}%\")\n",
    "print(f\"  â€¢ Predicted Churn Rate: {predicted_churn_rate:.2f}%\")\n",
    "print(f\"  â€¢ Model AUC-ROC: {auc:.3f}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_ML_Churn_Prediction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
